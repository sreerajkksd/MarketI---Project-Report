\section{Software requirement specification}
\subsection{Introduction}
\subsubsection{Purpose}
\par The purpose of this document is to provide a description of the ‘Market Intelligence using Graph database’. This system aims to build a graph database of different companies,  their products and the technologies on which they are working on. This document provides a detailed description of the features, working, requirement and scope of the product. It is intended for reference by users of the software and for those interested in studying the working of the system.
\subsubsection{Document convention}
Main Section Titles
\begin{itemize}
	\item Font: Times New Roman
	\item Face: Bold
	\item Size: 14
\end{itemize}
Sub Section Titles
\begin{itemize}
	\item Font: Times New Roman
	\item Face: Bold
	\item Size: 12
\end{itemize}
Other Text Explanations
\begin{itemize}
	\item Font: Times New Roman
	\item Face: Plain
	\item Size: 12
\end{itemize}
\subsubsection{Intended Audience and Reading Suggestions}
This Software Requirements Specification document is intended for:
\begin{itemize}
\item Developers who can review project’s capabilities and more easily understand where their efforts should be targeted to improve or add more features to it (design and code the application – it sets the guidelines for future development).
\item Project testers can use this document as a base for their testing strategy as some bugs are easier to find using a requirements document. This way testing becomes more methodically organized.
\item End users of this application who wish to read about what this project can do.
\end{itemize}
It is suggested to go through the document in the same sequence as it is written.
\subsubsection{Product scope}
\par This software system will finally create a graph database of companies, their products and the technologies in which these companies are working in. This software will be used by different company officials who are interested in knowing the different market movements and updates. Software will be provided as a SAAS platform in which the users can view the required portions of the graph and see their connections and updates. Querying the graph is allowed by the software which can help in navigating the nodes and associated relations. Users can identify the competitors of a product, company and companies working in a specific platform. It also shows the recent announcement of the company and news articles related to the company product info in the graph. It can also be used by different investors to help investing in successful firms according to the locations of the firm, recent advancements of the firm etc.
\subsection{Overall description}
\subsubsection{Product perspective}
\par This project Market intelligence using graph data is an entirely new product in this arena.   No other organization have come up with this sort of idea so far. This project have an over evolving database. In the coming years, text processing have unlimited possibilities database can be used to process corporate data according to the clients need. This project can perform in Business to Business basis
\subsubsection{Product functions}
\par The major part of this project is to process the corporate data. The data is fetched from
news articles and RSS feeds. Software’s will be provide provided as a SAAS platform in which the users the graph is allowed by the software see their connections and updates. Querying the graph is allowed by the software which can help in navigating the nodes and associated relations. Users can identify the competitors of a product, company and companies working in a
specific platform.
\subsubsection{User characteristics}
\par The users of this project are corporates and naïve users. Users can query the graph is allowed by the software which can help in navigating the nodes and associated relations. Users can identify the competitors of a product, company and companies working in a specific platform.

\subsubsection{Operating Environment}
Client:
\begin{itemize}
\item Software:
\begin{itemize}
\item Ubuntu 12.04
\item Windows XP and above
\end{itemize}
\item Hardware:
\begin{itemize}
\item RAM 2GB
\item Intel Core i3 processor and above
\end{itemize}
\end{itemize}
Server:
\begin{itemize}
\item Software:
\begin{itemize}
\item Ubuntu 14.04
\item Neo4j 2.2
\item Postgres 9.4
\item Java JDK 7
\end{itemize}
\item Hardware:
\begin{itemize}
\item RAM 8GB
\item HDD 8GB
\end{itemize}
\end{itemize}

\subsubsection{Design and implementation constraints}
\par The main design implementation difficulty is limitation of Natural language processing tools to extract the exact relations. Another difficulty is in processing eliminating the junk in the data obtained from websites.
\subsubsection{Assumption and dependency}
\par Our assumptions are the data obtained from news websites are legit and in format as we expect.

\subsection{External Interface Requirements}
\subsubsection{User Interface}
\par We provide a webpage in which the user can query different possibilities. A graph will be embedded in the webpage where users can query graphically. We also provide a website to display the recent activities taking place in the technology world.

\subsection{System Features}
\begin{itemize}
\item Dynamic and static data collection methods are built. Static data collector updates once in 2 or 3 months,while the dynamic collector will run every day.
\item Feed fetcher will parse the RSS feeds and extract the link. Rome API is used for this.
\item Webpage content extractor will fetch the news content from the webpage eliminating all garbages present in website. Google's Boilerpipe API is used for this.
\item NLP is the core module of this project. This will extract the entities as well as relations from the news website. This will be given to the graph updater. Graph updater will remove redundant relations and update it in the graph.
\item Neo4j is used as the graph database.PostgreSQL is used as live db which holds other informations
\end{itemize}

\subsection{Other Non-functional requirements}
\subsubsection{Performance requirements}
For operation involving graph querying especially when the number of nodes grows linearly with time, the system needs good processing power to perform in real-time. This requires  the installation of large main memories.

\subsubsection{Safety requirements}
\par There is no safety issues if this project is implemented correctly.
\subsubsection{Security Requirements}
\par Care should be taken to avoid any vulnerabilities in the website. The data obtained from feed fetch module must be correctly entered into the database. Since the accuracy of the NLP module is not certain, there will be privilege for the administrator to crosscheck the entries to the database.
\subsubsection{Business Rules}
\par During the initial training phase, operations are not done on the data fetched. We manually enter data, process it using NLP module and enter the data onto the graph database.

\subsection{Other Requirements}
\par Almost all requirements have been included earlier. If any, to be added further will be informed later.